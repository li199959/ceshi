{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3K2cD++B3roVy5xpYPK7D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugarforever/LangChain-Tutorials/blob/main/LangChain_Caching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding LangChain Caching\n",
        "\n",
        "In this notebook, we will see:\n",
        "1. How LangChain framework uses caching mechanism to improve LLM interaction efficiency.\n",
        "2. The caching algorithms of 2 different underlying storages, In-Memory and SQLite.\n",
        "\n",
        "Hope it will help you understand if and when you should use CACHE."
      ],
      "metadata": {
        "id": "oA823Xm-LG0c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VXeDv_iNy4Yt"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai --quiet --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = 'your openai api key'"
      ],
      "metadata": {
        "id": "EOakFOzKzApQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get your ChatOpenAI instance ready"
      ],
      "metadata": {
        "id": "GFr7TU4yMINW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI()"
      ],
      "metadata": {
        "id": "9dBrwRdizKI4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. In Memory Cache"
      ],
      "metadata": {
        "id": "U9LI6MsOMYDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.cache import InMemoryCache\n",
        "langchain.llm_cache = InMemoryCache()"
      ],
      "metadata": {
        "id": "pZkMY2T1zRJ4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ask a question and measure how long it takes for LLM to respond."
      ],
      "metadata": {
        "id": "A_0EEZ6BMgHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "llm.predict(\"What is OpenAI?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "EOxV7tZwz0Jz",
        "outputId": "9bb819c6-78f1-46e2-c7df-8ebcd1cc6f6a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 25 ms, sys: 6.4 ms, total: 31.4 ms\n",
            "Wall time: 4.54 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"OpenAI is an artificial intelligence research laboratory and company that aims to ensure that artificial general intelligence (AGI) benefits all of humanity. It was founded in December 2015 as a non-profit organization but later transformed into a for-profit company called OpenAI LP in 2019. OpenAI conducts research in various fields of AI, develops cutting-edge technologies, and publishes most of its AI research findings. The organization's mission is to ensure that AGI is developed safely, is aligned with human values, and is used for the benefit of all individuals.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How the cache stores data\n",
        "\n",
        "**source code**: [cache.py](https://github.com/hwchase17/langchain/blob/v0.0.219/langchain/cache.py#L102)\n",
        "```python\n",
        "class InMemoryCache(BaseCache):\n",
        "    \"\"\"Cache that stores things in memory.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Initialize with empty cache.\"\"\"\n",
        "        self._cache: Dict[Tuple[str, str], RETURN_VAL_TYPE] = {}\n",
        "```\n",
        "\n",
        "This is the implementation of InMemoryCache."
      ],
      "metadata": {
        "id": "wNVz-A70OB65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First element of the tuple\n",
        "list(langchain.llm_cache._cache.keys())[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "795SesMkKsx1",
        "outputId": "6602dee3-af40-4211-9ea6-c957c565babb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"HumanMessage\"], \"kwargs\": {\"content\": \"What is OpenAI?\"}}]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second element of the tuple\n",
        "list(langchain.llm_cache._cache.keys())[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "cKoCMgV1J0Qy",
        "outputId": "a3ae41b4-2983-458f-ee38-9d5390df660a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"openai_api_key\": {\"lc\": 1, \"type\": \"secret\", \"id\": [\"OPENAI_API_KEY\"]}}}---[(\\'stop\\', None)]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ask same question again and see the quicker response."
      ],
      "metadata": {
        "id": "s0HhgOmWMomV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "llm.predict(\"What is OpenAI?\")"
      ],
      "metadata": {
        "id": "GDykW5yiMw-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. SQLite as Cache"
      ],
      "metadata": {
        "id": "vYonfxGfMx3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f .cache.db"
      ],
      "metadata": {
        "id": "EP3QRaPy0mp1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.cache import SQLiteCache\n",
        "langchain.llm_cache = SQLiteCache(database_path=\".cache.db\")"
      ],
      "metadata": {
        "id": "yRFlThqU0tfU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ask the same question twice and measure the performance difference"
      ],
      "metadata": {
        "id": "2j1dHYmGM5WK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "llm.predict(\"What is OpenAI?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "WsfcYsU40yFR",
        "outputId": "e0128db0-d992-4037-c91d-b63847cf905b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.25 ms, sys: 980 Âµs, total: 5.23 ms\n",
            "Wall time: 4.97 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'OpenAI is an artificial intelligence research laboratory and company. It was founded in December 2015 with the goal of developing and promoting friendly AI for the benefit of all humanity. OpenAI conducts cutting-edge research in various areas of AI and aims to ensure that artificial general intelligence (AGI) benefits everyone and is used responsibly. They work on advancing AI technology, publishing most of their AI research, and providing public goods to help society navigate the path to AGI. OpenAI also develops and deploys AI models and systems, such as the language model GPT-3, to showcase the capabilities and potential applications of AI.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "llm.predict(\"What is OpenAI?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "m_HFoa-Z052V",
        "outputId": "728a714a-83d4-42fc-d289-c376915c0152"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 39.3 ms, sys: 9.16 ms, total: 48.5 ms\n",
            "Wall time: 4.84 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'OpenAI is an artificial intelligence research lab and company founded in December 2015. Its mission is to ensure that artificial general intelligence (AGI) benefits all of humanity. OpenAI conducts research to develop safe and beneficial AI technologies and also aims to promote the widespread adoption of such technologies for societal benefit. The organization has made significant contributions to the field of AI, particularly in areas such as natural language processing, reinforcement learning, and robotics. OpenAI also develops and maintains various open-source AI tools and frameworks to facilitate the development and deployment of AI applications.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add some space in the sentence and ask again"
      ],
      "metadata": {
        "id": "hHIjReJUM_gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "llm.predict(\"What is  OpenAI?\")"
      ],
      "metadata": {
        "id": "hdD1CpzSNFzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlalchemy\n",
        "from sqlalchemy import create_engine, text\n",
        "engine = create_engine(\"sqlite:///.cache.db\")"
      ],
      "metadata": {
        "id": "TvI7KFBLGfTn"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Why does the extra space cause the cache miss??**"
      ],
      "metadata": {
        "id": "Y4LAKj76NJiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How SQLite stores cache data\n",
        "\n",
        "**source code**: [cache.py](https://github.com/hwchase17/langchain/blob/v0.0.219/langchain/cache.py#L128)\n",
        "```python\n",
        "class FullLLMCache(Base):  # type: ignore\n",
        "    \"\"\"SQLite table for full LLM Cache (all generations).\"\"\"\n",
        "\n",
        "    __tablename__ = \"full_llm_cache\"\n",
        "    prompt = Column(String, primary_key=True)\n",
        "    llm = Column(String, primary_key=True)\n",
        "    idx = Column(Integer, primary_key=True)\n",
        "    response = Column(String)\n",
        "\n",
        "\n",
        "class SQLAlchemyCache(BaseCache):\n",
        "    \"\"\"Cache that uses SQAlchemy as a backend.\"\"\"\n",
        "\n",
        "    def __init__(self, engine: Engine, cache_schema: Type[FullLLMCache] = FullLLMCache):\n",
        "        \"\"\"Initialize by creating all tables.\"\"\"\n",
        "        self.engine = engine\n",
        "        self.cache_schema = cache_schema\n",
        "        self.cache_schema.metadata.create_all(self.engine)\n",
        "```\n",
        "\n",
        "This is the schema of cache table `full_llm_cache`."
      ],
      "metadata": {
        "id": "hlKSAcOOOSqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with engine.connect() as connection:\n",
        "\n",
        "    rs = connection.exec_driver_sql('select * from full_llm_cache')\n",
        "    print(rs.keys())\n",
        "    for row in rs:\n",
        "        print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK8cQdbkGrNk",
        "outputId": "4c986b1d-1dfb-49d8-caf3-66e9f03f62a0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMKeyView(['prompt', 'llm', 'idx', 'response'])\n",
            "('[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"HumanMessage\"], \"kwargs\": {\"content\": \"What is OpenAI?\"}}]', '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"openai_api_key\": {\"lc\": 1, \"type\": \"secret\", \"id\": [\"OPENAI_API_KEY\"]}}}---[(\\'stop\\', None)]', 0, '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"ChatGeneration\"], \"kwargs\": {\"message\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"lang ... (588 characters truncated) ... AI models and systems, such as the language model GPT-3, to showcase the capabilities and potential applications of AI.\", \"additional_kwargs\": {}}}}}')\n",
            "('[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"HumanMessage\"], \"kwargs\": {\"content\": \"What is  OpenAI?\"}}]', '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"openai_api_key\": {\"lc\": 1, \"type\": \"secret\", \"id\": [\"OPENAI_API_KEY\"]}}}---[(\\'stop\\', None)]', 0, '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"ChatGeneration\"], \"kwargs\": {\"message\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"lang ... (594 characters truncated) ...  maintains various open-source AI tools and frameworks to facilitate the development and deployment of AI applications.\", \"additional_kwargs\": {}}}}}')\n"
          ]
        }
      ]
    }
  ]
}